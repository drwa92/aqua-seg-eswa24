# Aquaculture Defects Recognition via Multi-Scale Semantic Segmentation

Semantic segmentation framework to detect **biofouling**, **vegetation**, and **net holes** on aquaculture net pens using underwater imagery.  
It implements a **multi-scale encoderâ€“decoder** with three custom blocksâ€”**Identity Block (IB)**, **Shape-Preservation Block (SPB)**, and **Hierarchical Decomposition Block (HDB)**â€”and a tailored **L_t** loss that blends two sub-objectives to handle class imbalance and stabilize convergence.

> ![](abstract-fig.png)

> This repository accompanies the paper *Akram, W., Hassan, T., Toubar, H., Ahmed, M., MiÅ¡kovic, N., Seneviratne, L., & Hussain, I. (2024). Aquaculture defects recognition via multi-scale semantic segmentation*. Expert systems with applications, 237, 121197.

---

## âœ¨ Highlights

- **Multi-scale encoderâ€“decoder**: fuses features from *multiple encoder depths* (â€œbutterflyâ€ topology) to be robust to noise and preserve defect shape.
- **Custom blocks**:
  - **IB** (residual-style) â†’ discriminative features while preserving geometry
  - **SPB** â†’ keeps the *shape* of defect regions
  - **HDB** â†’ fuses coarseâ†”fine representations across scales
- **L_t loss** (with weights Î²â‚, Î²â‚‚ and temperature Ï„) â†’ soft targets for stable learning under heavy background/foreground imbalance.
- **Validated on four datasets** with real fish-farm imagery:
  - **LABUST** (156,600 imgs): biofouling, vegetation
  - **KU** (37,926 imgs): vegetation, holes
  - **NDv1** (1,864 imgs): biofouling, vegetation
  - **NDv2** (1,411 imgs): biofouling, vegetation
- **Outperforms SOTA** on mAP across all four datasets (e.g., +6.58% on LABUST).

---

## ğŸ“š Datasets

| Dataset | Images | Biofouling | Vegetation | Holes | Notes |
|---|---:|:---:|:---:|:---:|---|
| LABUST | 156,600 | âœ“ | âœ“ | âœ— | Real fish farms (Cromaris, Croatia) |
| KU | 37,926 | âœ— | âœ“ | âœ“ | Khalifa University pool; strong disturbances |
| NDv1 | 1,864 | âœ“ | âœ“ | âœ— | Public (Roboflow); pixel-wise masks prepared by authors |
| NDv2 | 1,411 | âœ“ | âœ“ | âœ— | Public (Roboflow); pixel-wise masks prepared by authors |

> The paper reports pixel-wise annotations for NDv1/NDv2 and new releases of LABUST/KU dataset.

---

## ğŸ—ï¸ Architecture (at a glance)

- Encoder aggregates multi-resolution features; latent features are taken from **multiple depths** rather than only the top.
- **HDB** blends features with average pooling + conv + BN + ReLU across scales; **SPB** preserves geometry with residual fusion; **IB** follows a ResNet-style pattern.
- Decoder is asymmetric and upsamples via **strided convolutions** (not bilinear interpolation) for sharper masks.

> See Fig. 2 in the paper for the full diagram.
> ![Multi-scale encoderâ€“decoder architecture](Picture1.png)


---

## ğŸ§ª Reported Training Setup (from paper)

- **Environment**: Python 3.7.9, TensorFlow 2.1.0, CUDA 11.0, cuDNN 7.5
- **Optimizer**: ADADELTA (lr=1.00, Ï/decay=0.95)
- **Schedule**: 40 epochs, 512 iterations per epoch
- **Input size**: 576Ã—768Ã—3
- **Validation**: LABUST/KU use 20% of train for val; NDv1/NDv2 use official splits (363 val)

---

##  Results

<a id="fig-qual-1"></a>
<p align="center">
  <img src="Picture3.jpg" alt="Qualitative predictions with segmentation overlays (examples Aâ€“L)" width="1000">
</p>
<p align="center"><em>Figure 1. Qualitative examples showing underwater frames and predicted segmentation overlays (Aâ€“L).</em></p>

<a id="fig-qual-ndv2"></a>
<p align="center">
  <img src="qual_ndv2.png" alt="NDv2 qualitative grid with frames and predicted masks (Aâ€“X)" width="1000">
</p>
<p align="center"><em>Figure 2. NDv2 qualitative results (Aâ€“X). Left columns: sample frames; right columns: predicted masks.</em></p>

See Figures <a href="#fig-qual-1">1</a> and <a href="#fig-qual-ndv2">2</a> for qualitative segmentation performance.



